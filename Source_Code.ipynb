{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T08:37:24.047292Z",
     "iopub.status.busy": "2024-06-20T08:37:24.046859Z",
     "iopub.status.idle": "2024-06-20T08:37:26.302489Z",
     "shell.execute_reply": "2024-06-20T08:37:26.301320Z",
     "shell.execute_reply.started": "2024-06-20T08:37:24.047248Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import BaggingClassifier, GradientBoostingRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from xgboost import XGBClassifier\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from fairlearn.metrics import demographic_parity_ratio\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from fairlearn.postprocessing import ThresholdOptimizer, plot_threshold_optimizer\n",
    "# Load the datasets\n",
    "X = pd.read_csv(\"train.csv\")\n",
    "unexpected_values = ['0', '3']\n",
    "X['MARITAL_STATUS'] = X['MARITAL_STATUS'].replace(unexpected_values, np.nan)\n",
    "X.dropna(subset=['MARITAL_STATUS'],inplace=True)\n",
    "\n",
    "# Separate features and target variable\n",
    "y = X[['DEFAULT.PAYMENT.NEXT.MONTH']]\n",
    "\n",
    "# Drop 'ID',  'DEFAULT.PAYMENT.NEXT.MONTH' and 'EDUCATION', 'EDUCATION' is dropped due to its low feature imporatnce score\n",
    "X = X.drop(['ID', 'DEFAULT.PAYMENT.NEXT.MONTH', 'EDUCATION'], axis=1)\n",
    "numerical_features = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    #('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T06:20:46.756407Z",
     "iopub.status.busy": "2024-06-20T06:20:46.756000Z",
     "iopub.status.idle": "2024-06-20T06:43:52.537805Z",
     "shell.execute_reply": "2024-06-20T06:43:52.536737Z",
     "shell.execute_reply.started": "2024-06-20T06:20:46.756378Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150/150 [23:05<00:00,  9.24s/trial, best loss: -0.5342588526835975]\n",
      "Best hyperparameters: {'colsample_bylevel': 0.7455126867976273, 'colsample_bynode': 0.8023057861840502, 'colsample_bytree': 0.9237560913738425, 'gamma': 0.19318393866652434, 'learning_rate': 0.0008519957113860956, 'max_depth': 1, 'min_child_weight': 2.5367614847690176, 'n_estimators': 2, 'reg_alpha': 0.0392827338916632, 'reg_lambda': 2.7656564834187147}\n"
     ]
    }
   ],
   "source": [
    "space = {\n",
    "        'n_estimators': hp.choice('n_estimators', [400, 450, 500, 550, 600, 650]),\n",
    "        'max_depth': hp.choice('max_depth', range(3, 12)),\n",
    "        'learning_rate': hp.uniform('learning_rate', 0.0003, 0.008),\n",
    "        'min_child_weight': hp.uniform('min_child_weight', 1, 12),\n",
    "        'gamma': hp.loguniform('gamma', low=np.log(0.01), high=np.log(5)),  # Gamma from 0 to 5 (log-uniform)\n",
    "        'reg_alpha': hp.loguniform('reg_alpha', low=np.log(0.001), high=np.log(0.81)),  # Alpha from 0 to 0.8 (log-uniform)\n",
    "        'reg_lambda': hp.loguniform('reg_lambda', low=np.log(1), high=np.log(5)),\n",
    "        'colsample_bytree': hp.uniform('colsample_bytree', 0.6, 1.0),\n",
    "        'colsample_bynode': hp.uniform('colsample_bynode', 0.6, 1.0),\n",
    "        'colsample_bylevel': hp.uniform('colsample_bylevel', 0.6, 1.0)\n",
    "        }\n",
    "\n",
    "def objective(space):\n",
    "\n",
    "    mean_f1_scores = []\n",
    "\n",
    "    # Flatten the target variable y\n",
    "    y_data  = y.values.ravel()\n",
    "\n",
    "    # Calculate scale_pos_weight for XGBClassifier\n",
    "    scale_pos_weight = (len(y_data) - y_data.sum()) / y_data.sum()\n",
    "    model_xgb = XGBClassifier(scale_pos_weight=scale_pos_weight, objective=\"binary:logistic\",\n",
    "                                    random_state=42, **space)\n",
    "    # Perform stratified k-fold cross-validation\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train_skf = preprocessor.fit_transform(X.iloc[train_index])\n",
    "        X_test_skf = preprocessor.transform(X.iloc[test_index])\n",
    "        y_train_skf, y_test_skf = y.iloc[train_index], y.iloc[test_index]\n",
    "        y_train_skf = y_train_skf.values.ravel()\n",
    "        y_test_skf = y_test_skf.values.ravel()\n",
    "        sensitive_features_test = X.iloc[test_index]['SEX'].values\n",
    "        sensitive_features_train = X.iloc[train_index]['SEX'].values\n",
    "        # Initialize ThresholdOptimizer for fairness constraints\n",
    "        threshold_optimizer = ThresholdOptimizer(\n",
    "         estimator=model_xgb,\n",
    "         constraints=\"demographic_parity\",\n",
    "         prefit=False,objective='balanced_accuracy_score',\n",
    "         predict_method=\"predict\"\n",
    "     )\n",
    "\n",
    "        # Fit the model\n",
    "        threshold_optimizer.fit(X_train_skf, y_train_skf, sensitive_features=sensitive_features_train)\n",
    "\n",
    "        # Predict on the test set\n",
    "        y_pred_skf = threshold_optimizer.predict(X_test_skf, sensitive_features=sensitive_features_test, random_state=42)\n",
    "\n",
    "        # Calculate F1 score\n",
    "        f1 = f1_score(y_test_skf, y_pred_skf, average='binary')\n",
    "        mean_f1_scores.append(f1)\n",
    "\n",
    "    # Calculate mean F1 score\n",
    "    mean_f1 = np.mean(mean_f1_scores)\n",
    "    # Return loss (negative mean F1 score) and optimization status\n",
    "    return {'loss': -mean_f1, 'status': STATUS_OK}\n",
    "\n",
    "# Run hyperparameter optimization using Hyperopt\n",
    "trials = Trials()\n",
    "best_params = fmin(objective, space, rstate=np.random.default_rng(42), algo=tpe.suggest,\n",
    "                   max_evals=150, trials=trials)\n",
    "# Print best hyperparameters found\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T08:37:35.473970Z",
     "iopub.status.busy": "2024-06-20T08:37:35.472935Z",
     "iopub.status.idle": "2024-06-20T08:37:42.030714Z",
     "shell.execute_reply": "2024-06-20T08:37:42.029642Z",
     "shell.execute_reply.started": "2024-06-20T08:37:35.473935Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call evaluate function\n",
      "Mean_f1 score 0.5342588526835975\n",
      "Mean Parity ratio 0.9799749520231481\n"
     ]
    }
   ],
   "source": [
    "best_params = {'colsample_bylevel': 0.7455126867976273, 'colsample_bynode': 0.8023057861840502, \n",
    "               'colsample_bytree': 0.9237560913738425, 'gamma': 0.19318393866652434, 'learning_rate': 0.0008519957113860956,\n",
    "               'max_depth': 4, 'min_child_weight': 2.5367614847690176, 'n_estimators': 500, \n",
    "               'reg_alpha': 0.0392827338916632, 'reg_lambda': 2.7656564834187147}\n",
    "def evaluate():\n",
    "\n",
    "    mean_f1_scores = []\n",
    "    mean_parity_ratio = []\n",
    "    # Flatten the target variable y\n",
    "    y_data  = y.values.ravel()\n",
    "    # Calculate scale_pos_weight for XGBClassifier\n",
    "    scale_pos_weight = (len(y_data) - y_data.sum()) / y_data.sum()\n",
    "    # Initialize XGBClassifier with best hyperparameters\n",
    "    model_xgb=XGBClassifier (scale_pos_weight=scale_pos_weight, objective=\"binary:logistic\",\n",
    "                                    random_state=42, **best_params)\n",
    "    # Perform stratified k-fold cross-validation\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train_skf = preprocessor.fit_transform(X.iloc[train_index])\n",
    "        X_test_skf = preprocessor.transform(X.iloc[test_index])\n",
    "        sensitive_features_test = X.iloc[test_index]['SEX'].values\n",
    "        sensitive_features_train = X.iloc[train_index]['SEX'].values\n",
    "        y_train_skf, y_test_skf = y.iloc[train_index], y.iloc[test_index]\n",
    "        y_train_skf = y_train_skf.values.ravel() \n",
    "        y_test_skf = y_test_skf.values.ravel()\n",
    "        # Initialize ThresholdOptimizer for fairness constraints\n",
    "        threshold_optimizer = ThresholdOptimizer(\n",
    "         estimator=model_xgb,\n",
    "         constraints=\"demographic_parity\",\n",
    "         prefit=False,objective='balanced_accuracy_score',\n",
    "         predict_method=\"predict\"\n",
    "        )\n",
    "        # Fit the model\n",
    "        threshold_optimizer.fit(X_train_skf, y_train_skf, sensitive_features=sensitive_features_train)\n",
    "\n",
    "        # Predict on the test set\n",
    "        y_pred_skf = threshold_optimizer.predict(X_test_skf,sensitive_features=sensitive_features_test, random_state=42)\n",
    "\n",
    "        # Evaluate the model using F1 score and demographic parity ratio\n",
    "        f1 = f1_score(y_test_skf, y_pred_skf, average='binary')\n",
    "        mean_f1_scores.append(f1)\n",
    "        parity_ratio = demographic_parity_ratio(y_test_skf, y_pred_skf, sensitive_features=sensitive_features_test)\n",
    "        mean_parity_ratio.append(parity_ratio)\n",
    "\n",
    "    # Print mean F1 score and mean demographic parity ratio\n",
    "    print(\"Mean_f1 score\", np.mean(mean_f1_scores))\n",
    "    print(\"Mean Parity ratio\", np.mean(mean_parity_ratio))\n",
    "# Call the evaluate function\n",
    "print(\"call evaluate function\")\n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T08:41:42.630787Z",
     "iopub.status.busy": "2024-06-20T08:41:42.630412Z",
     "iopub.status.idle": "2024-06-20T08:41:43.791795Z",
     "shell.execute_reply": "2024-06-20T08:41:43.790793Z",
     "shell.execute_reply.started": "2024-06-20T08:41:42.630759Z"
    }
   },
   "outputs": [],
   "source": [
    "final = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Extract 'ID' for later use\n",
    "i = final['ID']\n",
    "\n",
    "# Remove 'ID'\n",
    "final = final.drop(['ID'], axis=1)\n",
    "\n",
    "# Transform features in the test set using the preprocessor fitted on the training data\n",
    "X_pre = preprocessor.fit_transform(X)\n",
    "final_pre = preprocessor.transform(final)\n",
    "\n",
    "# Extract sensitive features from the test and training data\n",
    "sensitive_features_final = final['SEX']\n",
    "sensitive_features_X = X['SEX']\n",
    "\n",
    "# Flatten the target variable y\n",
    "y_data = y.values.ravel()\n",
    "\n",
    "# Calculate scale_pos_weight for XGBClassifier\n",
    "scale_pos_weight = (len(y_data) - y_data.sum()) / y_data.sum()\n",
    "\n",
    "# Initialize XGBClassifier with best hyperparameters\n",
    "best_model = XGBClassifier(\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    objective=\"binary:logistic\",\n",
    "    random_state=42,\n",
    "    **best_params\n",
    ")\n",
    "\n",
    "# Initialize ThresholdOptimizer for fairness constraints\n",
    "threshold_optimizer = ThresholdOptimizer(\n",
    "    estimator=best_model,\n",
    "    constraints=\"demographic_parity\",\n",
    "    prefit=False,\n",
    "    objective='balanced_accuracy_score',\n",
    "    predict_method=\"predict\"\n",
    ")\n",
    "# Fit the threshold optimizer on the preprocessed training data\n",
    "threshold_optimizer.fit(X_pre, y_data, sensitive_features=sensitive_features_X)\n",
    "# Make predictions on the preprocessed test data\n",
    "final_predictions = threshold_optimizer.predict(final_pre, sensitive_features=sensitive_features_final,\n",
    "                                                random_state=42)\n",
    "# Create a DataFrame for the predictions\n",
    "predictions_df = pd.DataFrame({\n",
    "    'ID': i,\n",
    "    'DEFAULT.PAYMENT.NEXT.MONTH': final_predictions\n",
    "})\n",
    "# Save results to CSV file\n",
    "predictions_df.to_csv(\"/kaggle/working/submission_enigma.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4705216,
     "sourceId": 7992284,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
